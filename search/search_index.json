{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Representations for Learning and Language (ReLeLa) research group located within the Department of Computer Science (DCC) at the University of Chile studies the fields of representation learning and natural language processing, as well as other topics related to data science and artificial intelligence. Members Academic Staff Jorge P\u00e9rez Felipe Bravo-Marquez Claudio Guti\u00e9rrez Jocelyn Dunstan B\u00e1rbara Poblete Alexandre Bergel Andr\u00e9s Abeliuk Iv\u00e1n Sipir\u00e1n Benjam\u00edn Bustos Students PhD Students Juglar D\u00edaz Henry Rosales Camilo Garrido Hern\u00e1n Sarmiento Aym\u00e9 Arango Rolando Kindelan Jesus Perez-Martin Frank Zamora Masters Students Daniel Aguirre Jhonny Cerezo Juan-Pablo Silva Cristi\u00e1n Ahumada Mabel S\u00e1nchez Daniel Diomedi Mat\u00edas Rojas Jorge Ortiz Basti\u00e1n Matamala Gabriel Iturra Mauricio Araneda Undergrad Students Juan Andr\u00e9s Moreno V\u00edctor Caro Sebasti\u00e1n Donoso Vicente Oyanedel Jos\u00e9 Ca\u00f1ete Gabriel Chaper\u00f3n Ignacio Meza Alumni Constanza Fierro Pablo Badilla Cristi\u00e1n Tamblay Collaborators Mauricio Quezada Felipe Tobar Jos\u00e9 Manuel Saavedra Juan Manuel Barrios Mauricio Cerda Network Members of our group participate or interact with the following other research groups or centers: Millennium Institute for Foundational Research on Data Natural Language Processing @ CMM The Laboratory of Scientific Image Analysis (SCIAN-Lab) Grupo de Aprendizaje de M\u00e1quinas, infErencia y Se\u00f1ales (GAMES) Machine Learning Group - University of Waikato Impresee eCommerce Labs","title":"Home"},{"location":"#members","text":"","title":"Members"},{"location":"#academic-staff","text":"Jorge P\u00e9rez Felipe Bravo-Marquez Claudio Guti\u00e9rrez Jocelyn Dunstan B\u00e1rbara Poblete Alexandre Bergel Andr\u00e9s Abeliuk Iv\u00e1n Sipir\u00e1n Benjam\u00edn Bustos","title":"Academic Staff"},{"location":"#students","text":"","title":"Students"},{"location":"#phd-students","text":"Juglar D\u00edaz Henry Rosales Camilo Garrido Hern\u00e1n Sarmiento Aym\u00e9 Arango Rolando Kindelan Jesus Perez-Martin Frank Zamora","title":"PhD Students"},{"location":"#masters-students","text":"Daniel Aguirre Jhonny Cerezo Juan-Pablo Silva Cristi\u00e1n Ahumada Mabel S\u00e1nchez Daniel Diomedi Mat\u00edas Rojas Jorge Ortiz Basti\u00e1n Matamala Gabriel Iturra Mauricio Araneda","title":"Masters Students"},{"location":"#undergrad-students","text":"Juan Andr\u00e9s Moreno V\u00edctor Caro Sebasti\u00e1n Donoso Vicente Oyanedel Jos\u00e9 Ca\u00f1ete Gabriel Chaper\u00f3n Ignacio Meza","title":"Undergrad Students"},{"location":"#alumni","text":"Constanza Fierro Pablo Badilla Cristi\u00e1n Tamblay","title":"Alumni"},{"location":"#collaborators","text":"Mauricio Quezada Felipe Tobar Jos\u00e9 Manuel Saavedra Juan Manuel Barrios Mauricio Cerda","title":"Collaborators"},{"location":"#network","text":"Members of our group participate or interact with the following other research groups or centers: Millennium Institute for Foundational Research on Data Natural Language Processing @ CMM The Laboratory of Scientific Image Analysis (SCIAN-Lab) Grupo de Aprendizaje de M\u00e1quinas, infErencia y Se\u00f1ales (GAMES) Machine Learning Group - University of Waikato Impresee eCommerce Labs","title":"Network"},{"location":"courses/","text":"We teach the following courses: Deep Learning Natural Language Processing Data Mining Statistical Thinking","title":"Courses"},{"location":"projects/","text":"Spanish Word Embeddings AffectiveTweets BETO: Spanish BERT WEFE: The Word Embeddings Fairness Evaluation Framework","title":"Projects"},{"location":"publications/","text":"2020 P. B\u00e1ez, F. Villena, M. Rojas, M. Dur\u00e1n, and J. Dunstan The Chilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in Spanish , In Proceedings of the 3rd Clinical Natural Language Processing Workshop , November, 291-300, 2020. DOI:10.18653/v1/2020.clinicalnlp-1.32 ( pdf ) J. Diaz, B. Poblete, and F. Bravo-Marquez An Integrated Model for Textual Social Media Data with Spatio-Temporal Dimensions , In Information Processing & Management , Volume 57, Issue 5, 2020. DOI:10.1016/j.ipm.2020.102219 ( pdf ) D.G. Trye, A.S. Calude, F. Bravo-Marquez, and T.T. Keegan Hybrid Hashtags: #YouKnowYoureAKiwiWhen your Tweet contains M\u0101ori and English , In Frontiers in Artificial Intelligence, section Language and Computation Volume 3, Article 15, April 2020. DOI: 10.3389/frai.2020.00015. ( pdf | supplementary Material ) P. Badilla, F. Bravo-Marquez, and J. P\u00e9rez WEFE: The Word Embeddings Fairness Evaluation Framework In Proceedings of the 29th International Joint Conference on Artificial Intelligence and the 17th Pacific Rim International Conference on Artificial Intelligence (IJCAI-PRICAI 2020) , Yokohama, Japan. Pages 430-436. DOI:10.24963/ijcai.2020/60. Acceptance rate: 12.6%. ( pdf ),( code ). The Logical Expressiveness of Graph Neural Networks Pablo Barcel\u00f3, Egor V. Kostylev, Mikael Monet, Jorge P\u00e9rez, Juan Reutter and Juan-Pablo Silva, ICLR 2020 ( talk , slides , poster ) Spanish Pre-Trained BERT Model and Evaluation Data Jose Ca\u00f1ete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang and Jorge P\u00e9rez PML4DC @ ICLR 2020 ( talk , slides , code ) Predicting Unplanned Readmissions with Highly Unstructured Data Constanza Fierro, Jorge P\u00e9rez, and Javier Mora, AI4AH @ ICLR 2020. 2019 Jorge P\u00e9rez, Javier Marinkovi\u0107 and Pablo Barcel\u00f3, On the Turing Completeness of Modern Neural Network Architectures, ICLR 2019. ( pdf ) ( poster ) Aym\u00e9 Arango, Jorge P\u00e9rez, Barbara Poblete , Hate Speech Detection is Not as Easy as You May Think: A Closer Look at Model Validation, SIGIR 2019. ( pdf ) Pablo Barcel\u00f3, Nelson Higuera, Jorge P\u00e9rez and Bernardo Subercaseaux, Expressiveness of Matrix and Tensor Query Languages in terms of ML Operators, DEEM @ SIGMOD 2019. ( pdf ) ( slides ) F. Bravo-Marquez, E. Frank, B. Pfahringer, and S. M. Mohammad AffectiveTweets: a WEKA Package for Analyzing Affect in Tweets , In Journal of Machine Learning Research 20(92): Pages 1\u22126, 2019. ( pdf ) S. Lang, F. Bravo-Marquez, C. Beckham, M. Hall, and E. Frank WekaDeeplearning4j: a Deep Learning Package for Weka based on DeepLearning4j , In Knowledge-Based Systems , Volume 178, 15 August 2019, Pages 48-50. DOI: 10.1016/j.knosys.2019.04.013 ( pdf ) A. Ansell, F. Bravo-Marquez, and B. Pfahringer An ELMo-inspired approach to SemDeep-5's Word-in-Context task . In Proceedings of the 5th Workshop on Semantic Deep Learning (SemDeep-5) co-located with IJCAI 2019 in Macau, China. ( pdf ) D. Trye, A. S. Calude, F. Bravo-Marquez, and T. T Keegan M\u0101ori Loanwords: A Corpus of New Zealand English Tweets . In Proceedings of the 2019 ACL Student Research Workshop (SRW), Florence, Italy. ( pdf ) F. Villena and J. Dunstan Obtenci\u00f3n autom\u00e1tica de palabras clave en textos cl\u00ednicos: una aplicaci\u00f3n de procesamiento del lenguaje natural a datos masivos de sospecha diagn\u00f3stica en Chile . In Revista m\u00e9dica de Chile , Volume 147, 2019. DOI:http://dx.doi.org/10.4067/s0034-98872019001001229 ( pdf )","title":"Publications"},{"location":"publications/#2020","text":"P. B\u00e1ez, F. Villena, M. Rojas, M. Dur\u00e1n, and J. Dunstan The Chilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in Spanish , In Proceedings of the 3rd Clinical Natural Language Processing Workshop , November, 291-300, 2020. DOI:10.18653/v1/2020.clinicalnlp-1.32 ( pdf ) J. Diaz, B. Poblete, and F. Bravo-Marquez An Integrated Model for Textual Social Media Data with Spatio-Temporal Dimensions , In Information Processing & Management , Volume 57, Issue 5, 2020. DOI:10.1016/j.ipm.2020.102219 ( pdf ) D.G. Trye, A.S. Calude, F. Bravo-Marquez, and T.T. Keegan Hybrid Hashtags: #YouKnowYoureAKiwiWhen your Tweet contains M\u0101ori and English , In Frontiers in Artificial Intelligence, section Language and Computation Volume 3, Article 15, April 2020. DOI: 10.3389/frai.2020.00015. ( pdf | supplementary Material ) P. Badilla, F. Bravo-Marquez, and J. P\u00e9rez WEFE: The Word Embeddings Fairness Evaluation Framework In Proceedings of the 29th International Joint Conference on Artificial Intelligence and the 17th Pacific Rim International Conference on Artificial Intelligence (IJCAI-PRICAI 2020) , Yokohama, Japan. Pages 430-436. DOI:10.24963/ijcai.2020/60. Acceptance rate: 12.6%. ( pdf ),( code ). The Logical Expressiveness of Graph Neural Networks Pablo Barcel\u00f3, Egor V. Kostylev, Mikael Monet, Jorge P\u00e9rez, Juan Reutter and Juan-Pablo Silva, ICLR 2020 ( talk , slides , poster ) Spanish Pre-Trained BERT Model and Evaluation Data Jose Ca\u00f1ete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang and Jorge P\u00e9rez PML4DC @ ICLR 2020 ( talk , slides , code ) Predicting Unplanned Readmissions with Highly Unstructured Data Constanza Fierro, Jorge P\u00e9rez, and Javier Mora, AI4AH @ ICLR 2020.","title":"2020"},{"location":"publications/#2019","text":"Jorge P\u00e9rez, Javier Marinkovi\u0107 and Pablo Barcel\u00f3, On the Turing Completeness of Modern Neural Network Architectures, ICLR 2019. ( pdf ) ( poster ) Aym\u00e9 Arango, Jorge P\u00e9rez, Barbara Poblete , Hate Speech Detection is Not as Easy as You May Think: A Closer Look at Model Validation, SIGIR 2019. ( pdf ) Pablo Barcel\u00f3, Nelson Higuera, Jorge P\u00e9rez and Bernardo Subercaseaux, Expressiveness of Matrix and Tensor Query Languages in terms of ML Operators, DEEM @ SIGMOD 2019. ( pdf ) ( slides ) F. Bravo-Marquez, E. Frank, B. Pfahringer, and S. M. Mohammad AffectiveTweets: a WEKA Package for Analyzing Affect in Tweets , In Journal of Machine Learning Research 20(92): Pages 1\u22126, 2019. ( pdf ) S. Lang, F. Bravo-Marquez, C. Beckham, M. Hall, and E. Frank WekaDeeplearning4j: a Deep Learning Package for Weka based on DeepLearning4j , In Knowledge-Based Systems , Volume 178, 15 August 2019, Pages 48-50. DOI: 10.1016/j.knosys.2019.04.013 ( pdf ) A. Ansell, F. Bravo-Marquez, and B. Pfahringer An ELMo-inspired approach to SemDeep-5's Word-in-Context task . In Proceedings of the 5th Workshop on Semantic Deep Learning (SemDeep-5) co-located with IJCAI 2019 in Macau, China. ( pdf ) D. Trye, A. S. Calude, F. Bravo-Marquez, and T. T Keegan M\u0101ori Loanwords: A Corpus of New Zealand English Tweets . In Proceedings of the 2019 ACL Student Research Workshop (SRW), Florence, Italy. ( pdf ) F. Villena and J. Dunstan Obtenci\u00f3n autom\u00e1tica de palabras clave en textos cl\u00ednicos: una aplicaci\u00f3n de procesamiento del lenguaje natural a datos masivos de sospecha diagn\u00f3stica en Chile . In Revista m\u00e9dica de Chile , Volume 147, 2019. DOI:http://dx.doi.org/10.4067/s0034-98872019001001229 ( pdf )","title":"2019"},{"location":"seminars/","text":"We hold weekly meetings on Wednesdays at 3PM at Auditorio Philippe Frajolet (303) Tercer Piso Edificio Poniente Beauchef 851. Our meeting's calendar Some of our seminars are available in our Playlist . Minutas (In Spanish) 05/05/2021 Carolina Chiu habl\u00f3 sobre el testeo de word embeddings en el contexto cl\u00ednico. 21/04/2021 Cristi\u00e1n Candia (UDD) nos habl\u00f3 sobre su trabajo en \"Inteligencia Colectiva\". 14/04/2021 Gast\u00f3n L'huillier nos habl\u00f3 sobre Machine Learning Engineering, infraestructura y todos los desaf\u00edos de poner en modelos en producci\u00f3n. ( slides ) 24/03/2021 Andr\u00e9s Abeliuk present\u00f3 su l\u00ednea de investigaci\u00f3n en tema de polarizaci\u00f3n. 17/03/2021 Alan Ansell present\u00f3 su trabajo sobre PolyLM, un LM pol\u00edsemico ( video ) 29/01/2021 Felipe Bravo dio un tutorial introductorio a la inferencia Bayesiana. 20/01/2021 Daniel Diomedi present\u00f3 su charla de Tesis II sobre Question Answering sobre Wikidata usando Entity Linking and Neural Semantic Parsing. 13/01/2021 Javier Vera present\u00f3 su trabajo sobre Aproximaciones computacionales a la diversidad ling\u00fc\u00edstica de Sudam\u00e9rica (la charla fue grabada). 06/01/2021 Pablo Badilla present\u00f3 su trabajo sobre sesgo en word embeddings. 23/12/2020 Bernardo Subercaseaux nos habl\u00f3 de su trabajo de investigaci\u00f3n acerca de formalizaciones de interpretabilidad de modelos de aprendizaje autom\u00e1tico desde el punto de vista de la complejidad computacional (slides, video ) 17/12/2020 Jorge Ortiz nos habl\u00f3 sobre la ling\u00fc\u00edstica s\u00edstemico funcional y sus potenciales v\u00ednculos con NLP. ( slides , video ) 02/12/2020: Mat\u00edas Rojas present\u00f3 su charla de Tesis I de mag\u00edster sobre nested NER en el Chilean Waiting List Corpus. 11/11/2020: Cristi\u00e1n Tamblay present\u00f3 su trabajo de memoria sobre transferencia de modelos de sentimiento y emoci\u00f3n en distintos dominios. 23/09/2020: Hern\u00e1n Sarmiento practic\u00f3 su charla de propuesta de tesis doctoral titulada: \"A Domain-independent and Multilingual Approach for Crisis Event Detection and Understanding\" 09/09/2020: Cristian Ahumada present\u00f3 su charla de Tesis I de mag\u00edster titulada: \"Dise\u00f1o y desarrollo de una infraestructura computacional b\u00e1sica para el aprendizaje del Mapuzugun\".( slides ) 12/08/2020: Javier Mu\u00f1oz present\u00f3 su charla de Tesis I de mag\u00edster sobre multi-instance multi-label text classification para educaci\u00f3n especial. 05/08/2020: Frank Zamora practiced for his PhD qualification exam. He presented his work on Semantic Change Detection and his survey on word representations. 20/05/2020: Gonzalo Mena nos habl\u00f3 sobre \"M\u00e9todos de estad\u00edstica computacional y machine learning para las ciencias de la vida, con una aplicaci\u00f3n a COVID-19.\" ( slides ). 04/03/2020: Carlos Castillo ( Chato ) nos habl\u00f3 sobre \"Fairness and Transparency in Rankings\" ( slides ). 16/03/2019: Jos\u00e9 Lezama de la Universidad de la Rep\u00fablica in Uruguay nos present\u00f3 su trabajo publicado en ICLR titulado: Revisiting non-linear PCA with progressively grown autoencoders. 15/03/2019: Daniel Diomedi nos habl\u00f3 sobre su tema de tesis de mag\u00edster: Improving Question Answering Systems over Wikidata. 27/11/2019: Andr\u00e9s Abeliuk (University of Southern California), nos habl\u00f3 sobre el impacto de los algoritmos en la sociedad. M\u00e1s info . 16/10/2019: Rollan Rodr\u00edguez nos habl\u00f3 sobre m\u00e9todos de clasificaci\u00f3n usando topolog\u00eda. 09/10/2019: Felipe Gonz\u00e1lez (alumno de la USM) nos present\u00f3 su trabajo sobre privacidad en el caso de Cambridge Analytica en Twitter. Su trabajo hace uso de word embeddings y open coding para encontrar asociaciones entre t\u00e9rminos. 02/10/2019: Jorge nos habl\u00f3 sobre dos papers de la familia de BERT que est\u00e1n en revisi\u00f3n en ICLR: 1) ELECTRA y 2) ALBERT . Idea interesante de ELECTRA: tener dos redes adversariales donde la primera genera oraciones corrompidas pero altamente probables (se reemplazan ciertas palabras por un muestreo de la salida de una softmax). Esto reemplaza la idea de hacer masking en BERT. La segunda red recibe las oraciones corrompidas de la primera y aprende a discriminar las palabras originales de las falsas (esto se hace con un sigmoide). Idea interesante de ALBERT: usar un embedding layer de menor dimensionalidad que se aumenta luego con una capa de proyecci\u00f3n. Esto reduce el n\u00famero de par\u00e1metros respecto a BERT. Adem\u00e1s se propone reemplazar la task de next sentence prediction por una que tome dos oraciones consecutivas, las desordene en algunos casos, y prediga si tienen el orden correcto. El argumento es que la tarea de next sentence prediction de BERT (que pone pares de oraciones aleatorias en los ejemplos negativos) es un muy simple. 25/09/2019: Wladmir Cardoso Brand\u00e3o present\u00f3 InferSent , una t\u00e9cnica para entrenar sentence embeddings usando datos de la Natural Language Inference task. 11/09/2019: Henry Rosales present\u00f3 su art\u00edculo publicado en EMNLP sobre Entity Linking. 04/09/2019: vimos la segunda parte del video de MultiTask Learning. Algunos conceptos interesantes: pointer networks (capas basadas en atenci\u00f3n para copiar partes del input), anti-curriculum training (aprender primero lo m\u00e1s d\u00edficil para evitar quedar en \u00f3ptimo local). 28/08/2019: Jorge di\u00f3 una clase sobre XLNet . Para llegar a XLNet hizo un repaso sobre Attention, Transformer y BERT . Cosas destacables sobre XLNet: relative positional encoding y permutation language models. Un blog post que trata de digerir esto aqu\u00ed . 21/08/2019: Daniel Aguirre present\u00f3 su charla de tesis I de mag\u00edster sobre Transformers para resolver tareas algor\u00edtmicas. 14/08/2019: Vimos este video sobre MultiTask learning de Richard Socher. Alcanzamos a ver la primera mitad. Lo paramos varias veces para procesarlo. La idea es usar QA como una tarea global donde se pueden instanciar muchas tareas de NLP (e.g., translation, entailment, sentiment analysis). M\u00e1s info en http://decanlp.com/ . Quedamos en retomar el video m\u00e1s adelante y leer el paper con m\u00e1s profundidad. 07/08/2019: Pablo Badilla present\u00f3 su propuesta de Tesis de Mag\u00edster sobre bias en Word Embeddings.","title":"Seminars"},{"location":"seminars/#minutas-in-spanish","text":"05/05/2021 Carolina Chiu habl\u00f3 sobre el testeo de word embeddings en el contexto cl\u00ednico. 21/04/2021 Cristi\u00e1n Candia (UDD) nos habl\u00f3 sobre su trabajo en \"Inteligencia Colectiva\". 14/04/2021 Gast\u00f3n L'huillier nos habl\u00f3 sobre Machine Learning Engineering, infraestructura y todos los desaf\u00edos de poner en modelos en producci\u00f3n. ( slides ) 24/03/2021 Andr\u00e9s Abeliuk present\u00f3 su l\u00ednea de investigaci\u00f3n en tema de polarizaci\u00f3n. 17/03/2021 Alan Ansell present\u00f3 su trabajo sobre PolyLM, un LM pol\u00edsemico ( video ) 29/01/2021 Felipe Bravo dio un tutorial introductorio a la inferencia Bayesiana. 20/01/2021 Daniel Diomedi present\u00f3 su charla de Tesis II sobre Question Answering sobre Wikidata usando Entity Linking and Neural Semantic Parsing. 13/01/2021 Javier Vera present\u00f3 su trabajo sobre Aproximaciones computacionales a la diversidad ling\u00fc\u00edstica de Sudam\u00e9rica (la charla fue grabada). 06/01/2021 Pablo Badilla present\u00f3 su trabajo sobre sesgo en word embeddings. 23/12/2020 Bernardo Subercaseaux nos habl\u00f3 de su trabajo de investigaci\u00f3n acerca de formalizaciones de interpretabilidad de modelos de aprendizaje autom\u00e1tico desde el punto de vista de la complejidad computacional (slides, video ) 17/12/2020 Jorge Ortiz nos habl\u00f3 sobre la ling\u00fc\u00edstica s\u00edstemico funcional y sus potenciales v\u00ednculos con NLP. ( slides , video ) 02/12/2020: Mat\u00edas Rojas present\u00f3 su charla de Tesis I de mag\u00edster sobre nested NER en el Chilean Waiting List Corpus. 11/11/2020: Cristi\u00e1n Tamblay present\u00f3 su trabajo de memoria sobre transferencia de modelos de sentimiento y emoci\u00f3n en distintos dominios. 23/09/2020: Hern\u00e1n Sarmiento practic\u00f3 su charla de propuesta de tesis doctoral titulada: \"A Domain-independent and Multilingual Approach for Crisis Event Detection and Understanding\" 09/09/2020: Cristian Ahumada present\u00f3 su charla de Tesis I de mag\u00edster titulada: \"Dise\u00f1o y desarrollo de una infraestructura computacional b\u00e1sica para el aprendizaje del Mapuzugun\".( slides ) 12/08/2020: Javier Mu\u00f1oz present\u00f3 su charla de Tesis I de mag\u00edster sobre multi-instance multi-label text classification para educaci\u00f3n especial. 05/08/2020: Frank Zamora practiced for his PhD qualification exam. He presented his work on Semantic Change Detection and his survey on word representations. 20/05/2020: Gonzalo Mena nos habl\u00f3 sobre \"M\u00e9todos de estad\u00edstica computacional y machine learning para las ciencias de la vida, con una aplicaci\u00f3n a COVID-19.\" ( slides ). 04/03/2020: Carlos Castillo ( Chato ) nos habl\u00f3 sobre \"Fairness and Transparency in Rankings\" ( slides ). 16/03/2019: Jos\u00e9 Lezama de la Universidad de la Rep\u00fablica in Uruguay nos present\u00f3 su trabajo publicado en ICLR titulado: Revisiting non-linear PCA with progressively grown autoencoders. 15/03/2019: Daniel Diomedi nos habl\u00f3 sobre su tema de tesis de mag\u00edster: Improving Question Answering Systems over Wikidata. 27/11/2019: Andr\u00e9s Abeliuk (University of Southern California), nos habl\u00f3 sobre el impacto de los algoritmos en la sociedad. M\u00e1s info . 16/10/2019: Rollan Rodr\u00edguez nos habl\u00f3 sobre m\u00e9todos de clasificaci\u00f3n usando topolog\u00eda. 09/10/2019: Felipe Gonz\u00e1lez (alumno de la USM) nos present\u00f3 su trabajo sobre privacidad en el caso de Cambridge Analytica en Twitter. Su trabajo hace uso de word embeddings y open coding para encontrar asociaciones entre t\u00e9rminos. 02/10/2019: Jorge nos habl\u00f3 sobre dos papers de la familia de BERT que est\u00e1n en revisi\u00f3n en ICLR: 1) ELECTRA y 2) ALBERT . Idea interesante de ELECTRA: tener dos redes adversariales donde la primera genera oraciones corrompidas pero altamente probables (se reemplazan ciertas palabras por un muestreo de la salida de una softmax). Esto reemplaza la idea de hacer masking en BERT. La segunda red recibe las oraciones corrompidas de la primera y aprende a discriminar las palabras originales de las falsas (esto se hace con un sigmoide). Idea interesante de ALBERT: usar un embedding layer de menor dimensionalidad que se aumenta luego con una capa de proyecci\u00f3n. Esto reduce el n\u00famero de par\u00e1metros respecto a BERT. Adem\u00e1s se propone reemplazar la task de next sentence prediction por una que tome dos oraciones consecutivas, las desordene en algunos casos, y prediga si tienen el orden correcto. El argumento es que la tarea de next sentence prediction de BERT (que pone pares de oraciones aleatorias en los ejemplos negativos) es un muy simple. 25/09/2019: Wladmir Cardoso Brand\u00e3o present\u00f3 InferSent , una t\u00e9cnica para entrenar sentence embeddings usando datos de la Natural Language Inference task. 11/09/2019: Henry Rosales present\u00f3 su art\u00edculo publicado en EMNLP sobre Entity Linking. 04/09/2019: vimos la segunda parte del video de MultiTask Learning. Algunos conceptos interesantes: pointer networks (capas basadas en atenci\u00f3n para copiar partes del input), anti-curriculum training (aprender primero lo m\u00e1s d\u00edficil para evitar quedar en \u00f3ptimo local). 28/08/2019: Jorge di\u00f3 una clase sobre XLNet . Para llegar a XLNet hizo un repaso sobre Attention, Transformer y BERT . Cosas destacables sobre XLNet: relative positional encoding y permutation language models. Un blog post que trata de digerir esto aqu\u00ed . 21/08/2019: Daniel Aguirre present\u00f3 su charla de tesis I de mag\u00edster sobre Transformers para resolver tareas algor\u00edtmicas. 14/08/2019: Vimos este video sobre MultiTask learning de Richard Socher. Alcanzamos a ver la primera mitad. Lo paramos varias veces para procesarlo. La idea es usar QA como una tarea global donde se pueden instanciar muchas tareas de NLP (e.g., translation, entailment, sentiment analysis). M\u00e1s info en http://decanlp.com/ . Quedamos en retomar el video m\u00e1s adelante y leer el paper con m\u00e1s profundidad. 07/08/2019: Pablo Badilla present\u00f3 su propuesta de Tesis de Mag\u00edster sobre bias en Word Embeddings.","title":"Minutas (In Spanish)"}]}