
We hold weekly meetings on Wednesdays at 3PM at Auditorio Philippe Frajolet (303) Tercer Piso Edificio Poniente Beauchef 851.



Our meeting's [calendar](https://calendar.google.com/calendar?cid=a2RodGsyMzZoOGdoc21nc3BscG9hMXBwaDRAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ)

Some of our seminars are available in our [Playlist](https://youtube.com/playlist?list=PLppKo85eGXiWOuXni-PIyPu7V63RhqbKJ).

## Minutas (In Spanish)
1. 22/06/2022 [Juan Pablo Silva](https://jpsilva.cl/) presentó su charla de Tesis II de magíster titulada: "Logic-based interpretability of Graph Neural Networks"
1. 28/04/2022 [Miguel Cordero](https://orcid.org/0000-0003-4414-4447) del Servicio de Salud Metropolitano Sur Oriente de Santiago de Chile, nos presentó "Tendencias de la salud mental en los primeros 20 años de vida de usuarios/as de servicios de salud en el sur oriente de Santiago: ¿qué podemos aprender de las notas medicas?" 
1. 05/01/2022 Rolando Kindelan nos dió una charla titulado "Análisis Topológico de Datos (TDA): antecedentes, actualidad y perspectivas"
1. 22/12/2021 El alumno de magíster José Cañete presentó su charla de tesis I: "Efficient models for Spanish NLP through Knowledge Distillation"
1. 15/12/2021 El alumno de magíster Matías Rojas presentó su charla de tesis II titulada: Nested named entity recognition in diagnoses from the Chilean Waiting List in public hospitals  ([slides](slides/matiasrojastesisII.pdf))
1. 01/12/2021 Los alumnos de magíster Humberto Rodrigues y David Rojas presentaron sus charlas de Tesis I tituladas "Exploring bias metric strategies in contextualized embeddings" y "Word Embedding Bias Origin Detection".
1. 19/11/2021 Javier Muñoz presentó su trabajo de tesis de magíster: "Aprendizaje multi-instancia multi-etiqueta en la recomendación de intervenciones"
1. 29/09/2021 Cristian Ahumada presentó su trabajo: "Diseño y desarrollo de un software de apoyo para el aprendizaje del Mapuzugun"
1. 22/09/2021 Mauricio Araneda presentó un tutorial sobre VAEs. ([slides](slides/understanding_variational_encoders.pdf))
1. 01/09/2021 Pablo Badilla nos habló sobre su trabajo en el proyecto "lxs 400 "
1. 07/07/2021 Los alumnos de magíster Bastián Matamala, Mauricio Araneda y Gabriel Iturra presentaron sus charlas de Tesis I.
1. 05/05/2021  Carolina Chiu habló sobre el testeo de word embeddings en el contexto clínico. 
1. 21/04/2021 [Cristián Candia](https://crcandia.github.io/crcandiav/) (UDD) nos habló sobre su trabajo en "Inteligencia Colectiva".
1. 14/04/2021 Gastón L'huillier nos habló sobre Machine Learning Engineering, infraestructura y todos los desafíos de poner en modelos en producción. ([slides](slides/Machine_Learning_Engineering_Gaston.pdf))
1. 24/03/2021 Andrés Abeliuk presentó su línea de investigación en tema de polarización.
1. 17/03/2021 Alan Ansell presentó su trabajo sobre PolyLM, un LM polísemico ([video](https://youtu.be/OKD8fvNZVwE))
1. 29/01/2021 Felipe Bravo dio un tutorial introductorio a la inferencia Bayesiana.
1. 20/01/2021 Daniel Diomedi presentó su charla de Tesis II sobre Question Answering sobre Wikidata usando Entity Linking and Neural Semantic Parsing.
1. 13/01/2021 Javier Vera presentó su trabajo sobre Aproximaciones computacionales a la diversidad lingüística de Sudamérica (la charla fue grabada).
1. 06/01/2021 Pablo Badilla presentó su trabajo sobre sesgo en word embeddings.
1. 23/12/2020 Bernardo Subercaseaux nos habló de su trabajo de investigación acerca de formalizaciones de interpretabilidad de modelos de aprendizaje automático desde el punto de vista de la complejidad computacional (slides, [video](https://youtu.be/7ZfDaFccl-8))
1. 17/12/2020 Jorge Ortiz nos habló sobre la lingüística sístemico funcional y sus potenciales vínculos con NLP. ([slides](https://ortizfuentes.com/wp-content/uploads/2020/12/Ortiz-J.-2020-Charla-El-aporte-de-los-estudios-del-lenguaje.pdf),[video](https://youtu.be/jRWyPl6cb7I))
1. 02/12/2020: Matías Rojas presentó su charla de Tesis I de magíster sobre nested NER en el Chilean Waiting List Corpus.
1. 11/11/2020: Cristián Tamblay presentó su trabajo de memoria sobre transferencia de modelos de sentimiento y emoción en distintos dominios.
1. 23/09/2020: Hernán Sarmiento practicó su charla de propuesta de tesis doctoral titulada: "A Domain-independent and Multilingual Approach for Crisis Event Detection and Understanding"
1. 09/09/2020: Cristian Ahumada presentó su charla de Tesis I de magíster titulada: "Diseño y desarrollo de una infraestructura computacional básica para el aprendizaje del Mapuzugun".([slides](slides/CharlaMapuzugun.pdf))
1. 12/08/2020: Javier Muñoz presentó su charla de Tesis I de magíster sobre multi-instance multi-label text classification para educación especial.
1. 05/08/2020: Frank Zamora practiced for his PhD qualification exam. He presented his work on Semantic Change Detection and his survey on word representations.
1. 20/05/2020: [Gonzalo Mena](https://gomena.github.io/) nos habló sobre "Métodos de estadística computacional y machine learning para las ciencias de la vida, con una aplicación a COVID-19." ([slides](slides/charla_gonzalo_mena.pdf)).
1. 04/03/2020: Carlos Castillo ([Chato](https://chato.cl/)) nos habló sobre "Fairness and Transparency in Rankings" ([slides](https://docs.google.com/presentation/d/1g8fKO8sL5zSTf4WMpziy-LiQrOI1rpHXpv9sZ2fljE0/edit?usp=sharing)).
1. 16/03/2019: [José Lezama](https://scholar.google.com/citations?user=iDP84cQAAAAJ&hl=en&oi=sra) de la Universidad de la República in Uruguay nos presentó su trabajo publicado en ICLR titulado: Revisiting non-linear PCA with progressively grown autoencoders.
1. 15/03/2019: Daniel Diomedi nos habló sobre su tema de tesis de magíster:  Improving Question Answering Systems over Wikidata.
1. 27/11/2019:  Andrés Abeliuk (University of Southern California), nos habló sobre el impacto de los algoritmos en la sociedad. Más [info](https://www.dcc.uchile.cl/charla-impacto-de-los-algoritmos-en-la-sociedad).
1. 16/10/2019: Rollan Rodríguez nos habló sobre métodos de clasificación usando topología.
1. 09/10/2019: Felipe González (alumno de la USM) nos presentó su trabajo sobre privacidad en el caso de Cambridge Analytica en Twitter. Su trabajo hace uso de word embeddings y open coding para encontrar asociaciones entre términos. 
1. 02/10/2019: Jorge nos habló sobre dos papers de la familia de BERT que están en revisión en ICLR: 1) [ELECTRA](https://openreview.net/forum?id=r1xMH1BtvB) y 2) [ALBERT](https://openreview.net/forum?id=H1eA7AEtvS). 
	1.  Idea interesante de ELECTRA: tener dos redes adversariales donde la primera genera oraciones corrompidas pero altamente probables (se reemplazan ciertas palabras por un muestreo de la salida de una softmax). Esto reemplaza la idea de hacer masking en BERT. La segunda red recibe las oraciones corrompidas de la primera y aprende a discriminar las palabras originales de las falsas (esto se hace con un sigmoide). 
	1. Idea interesante de ALBERT: usar un embedding layer de menor dimensionalidad que se aumenta luego con una capa de proyección. Esto reduce el número de parámetros respecto a BERT. Además se propone reemplazar la task de next sentence prediction por una que tome dos oraciones consecutivas, las desordene en algunos casos, y prediga si tienen el orden correcto. El argumento es que la tarea de next sentence prediction de BERT (que pone pares de oraciones aleatorias en los ejemplos negativos) es un muy simple. 
1. 25/09/2019: [Wladmir Cardoso Brandão](http://www.wladmirbrandao.com) presentó [InferSent](https://github.com/facebookresearch/InferSent), una técnica para entrenar sentence embeddings usando datos de la Natural Language Inference task.
1. 11/09/2019: Henry Rosales presentó su artículo publicado en EMNLP sobre Entity Linking.
1. 04/09/2019: vimos la segunda parte del video de MultiTask Learning. Algunos conceptos interesantes: pointer networks (capas basadas en atención para copiar partes del input), anti-curriculum training (aprender primero lo más díficil para evitar quedar en óptimo local).
1. 28/08/2019: Jorge dió una clase sobre [XLNet](https://github.com/zihangdai/xlnet). Para llegar a XLNet hizo un repaso sobre Attention, Transformer y [BERT](https://arxiv.org/abs/1810.04805). Cosas destacables sobre XLNet: relative positional encoding y permutation language models. Un blog post que trata de digerir esto [aquí](http://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/).
1. 21/08/2019: Daniel Aguirre presentó su charla de tesis I de magíster sobre Transformers para resolver tareas algorítmicas. 
1. 14/08/2019: Vimos [este](https://www.youtube.com/watch?v=M8dsZsEtEsg&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=18&t=0s) video sobre MultiTask learning de Richard Socher. Alcanzamos a ver la primera mitad. Lo paramos varias veces para procesarlo. La idea es usar QA como una tarea global donde se pueden instanciar muchas tareas de NLP (e.g., translation, entailment, sentiment analysis). Más info en [http://decanlp.com/](http://decanlp.com/). Quedamos en retomar el video más adelante y leer el paper con más profundidad.
1. 07/08/2019: Pablo Badilla presentó su propuesta de Tesis de Magíster sobre bias en Word Embeddings.
