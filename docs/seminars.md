We hold weekly meetings on Wednesdays at 3PM at Auditorio Philippe Frajolet (303) Tercer Piso Edificio Poniente Beauchef 851.

Our meeting's [calendar](https://calendar.google.com/calendar?cid=a2RodGsyMzZoOGdoc21nc3BscG9hMXBwaDRAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ)

Some of our seminars are available in our [Playlist](https://youtube.com/playlist?list=PLppKo85eGXiWOuXni-PIyPu7V63RhqbKJ).

## Minutas (In Spanish)

1. 21/08/2024 María José Zambrano presentó su charla de tesis II, titulada: Towards Fairer Word Embeddings: Methodologies for Comparing and Optimizing Bias Mitigation Algorithms ([slides](slides/presentation%20tesis%20II-1.pdf)). 
1. 10/07/2024 [Fabián Villena](https://villena.cl/) presentó su seminario titulado: Despliegue local de grandes modelos de lenguaje de pesos libres y su consumo ([slides](slides/llm_deployment_and_consumption_tutorial.pdf))([video](https://drive.google.com/file/d/1a7rF6Chr18PTB-KbFvftVGla_kOIhX3y/view?usp=sharing)).
1. 12/06/2024 Andrés Abeliuk presentó su seminario titulado: LLMs, Una Perspectiva desde la Ciencia de la Complejidad ([slides](slides/RELELA-24LLM%20complexity.pdf))([video](https://drive.google.com/file/d/1ekFaSkY1fJZUyrM5CD0PQuLBO7v6hLOY/view?usp=sharing))
1. 26/12/2023 Germán Johannsen del Max Planck Institute for Innovation and Competition presentó: Regulación de IA y Datos. Algunas Tendencias en la UE ([slides](slides/charlaGerman.pdf)).
2. 14/12/2023 [Felipe Bravo-Marquez](https://felipebravom.com/), en conjunto con el CENIA, presentó su seminario titulado: Natural Language Processing Large Language Models Usage and Evaluation Patterns ([slides](slides/NLP-LLMpatterns.pdf))([video](https://www.youtube.com/watch?v=l2WpZC4dBAs&feature=youtu.be)).
3. 29/11/2023 [Felipe Urrutia](https://www.dim.uchile.cl/~furrutia/) presentó su seminario titulado: Deep Natural Language Feature Learning for Interpretable Prediction presentado en la Conferencia Internacional EMNLP 2024 ([slides](slides/EMNLP_NLLF_presentation.pdf)).
4. 24/10/2023 [Felipe Bravo-Marquez](https://felipebravom.com/) presentó su seminario titulado Un recorrido por los modelos de lenguaje: Desde Shannon a GPT-4 en las [JJC 2023](https://jcc2023.cl/) ([slides](slides/HistoriaLM.pdf)).
5. 02/08/2023 Ricardo Baeza-Yates presentó su seminario titulado: Inteligencia Artificial Responsable ([video](https://www.youtube.com/watch?v=e50G7mIEvoY&ab_channel=DCCUChile)).
6. 10/07/2023 Mircea Petrache presentó su seminario titulado: Conformal Language Modeling ([slides](slides/mircea-petrache-seminarII.pdf)).
7. 07/05/2023 Edison Marrese-Taylor presentó su seminario titulado: Learning to Represent Edits ([slides](slides/seminar-edison-marrese-taylor.pdf)).
8. 31/05/2023 Ciclo de charlas ChatGPT: Panel de Discusión - Alcances y límites de los modelos de lenguaje.
    * Panelitas: 
        * Cristián Buc (CENIA), [slides](slides/ciclo/seminar-cristian-buc.pdf) mini-presentación.
        * Magdalena Saldaña (UC/IMFD).
        * Martín Cáceres (MINEDUC).
        * Felipe Tobar (IDIA Uchile, CMM).
    * Moderador: Claudio Gutiérrez (DCC-IMFD).
9. 24/05/2023 Ciclo de charlas ChatGPT en la Industria: posibilidades y proyecciones ([video](https://www.youtube.com/watch?v=nsHBAVzSKOs&t=464s)):
    * Jorge Peréz presentó su seminario: IA sin farándula ([slides](slides/ciclo/seminar-jorge-perez.pdf)).
    * Manuel Peña presentó su seminario: GPT y Agentes, Como Conversar con tu App ([slides](slides/ciclo/seminar-manuel-pena.pdf)). 
10. 17/05/2023 Ciclo de Charlas de ChatGPT: Gabriela Arriagada presentó su seminario, Desafíos éticos actuales a la luz de la revolución sociotecnológica del GPT3 y 4 ([slides](slides/ciclo/seminar-gabriela-arriagada.pdf))([video](https://www.youtube.com/watch?v=2tBIj2lTApI&t=99s)).
11. 10/05/2023 Ciclo de Charlas ChatGPT: Felipe Bravo presentó su seminario titulado, Un recorrido por los Modelos de Lenguaje: desde Shannon a GPT-4 ([slides](slides/ciclo/seminar-felipe-bravo.pdf))([video](https://www.youtube.com/live/XvXeSwO_9ds?feature=share)).
12. 04/05/2023 Ciclo de Charlas ChatGPT: Jorge Ortiz presentó su seminario titulado, ¿Puede ChatGPT conquistar el mundo?
   Lenguaje humano vs lenguaje de máquina ([slides](slides/ciclo/seminar-jorge-ortiz.pdf))([video](https://www.youtube.com/watch?v=ow1QV5lqQ-E)).
13. 26/04/2023 Mauricio Araneda presentó su seminario titulado: MUSIB: Musical Score Inpainting Benchmark ([slides](slides/mauricio-araneda-seminar.pdf)).
14. 19/04/2023 Felipe Urrutia presentó su seminario titulado: The Role of Natural Language Processing in Advancing Competency-Based Education and Mathematics Learning in Fourth Graders ([slides](slides/seminar-felipe-urrutia.pdf))
15. 12/04/2023 [Gabriel Iturra](https://giturra.cl/) presentó su charla de tesis II titulada: RiverText: A Framework for Training and Evaluating Incremental Word Embeddings from Text Data Streams ([slides](slides/gabrieliturratesisII.pdf))([vídeo](https://www.youtube.com/watch?v=T0RD3mULe5M)).
16. 05/04/2023 Valentin Barriere presentó su seminario titulada: Multilingual Multi-target Stance Recognition
   in Online Public Consultations ([slides](slides/charla_valentin_barriere.pdf))
17. 29/03/2023 José Cañete presentó su charla de tesis II titulada: Light and Fast Language Models for
   Spanish Through Compression
   Techniques ([slides](slides/joseca%C3%B1etertesisII.pdf))([video](https://www.youtube.com/watch?v=qKSfwKv3e-0)).
18. 25/01/2023 Valentin Barriere presentó su seminario titulado: Two improvements for mutli-lingual in-context
   classification over tweets using transformers ([slides](slides/tweetalk.pdf)).
19. 18/01/2023 Presentaciones relámpago de los miembros de Relela ([slides](slides/presentaciones.pdf)).
20. 11/01/2023 Mircea Petrache presentó su seminario titulada: Word embeddings analogies and paraphrases: proofs and open problems ([slides](slides/2023-11-01MirceaPetrocha.pdf)).
21. 04/01/2023 Se realizo una reunión de coordinación para futuras actividades Relela, donde se tomaron los siguientes acuerdos:

       * Evento con presentaciones relámpagos sobre el tema que cada uno trabaja (2 minutos de presentación con 1 diapositiva).
       * Profesores de ReLeLa incorporarán a sus estudiantes.
       * Presentación periodica de papers (semanal).
       * Definir roles en el grupo.
       
22. 21/12/2022 Se presentaron 2 charlas de Tesis I de magíster, 1) Clemente Henríquez: Evolution of topic and issues in Chilean news ([slides](slides/presentacion.pdf)), 2) Ignacio Meza: Benchmarking video action features for the video temporary sentence grounding task ([slides](slides/Benchmarking_video_action_features_for_the_video_temporary_sentence.pdf)).
23. 14/12/2022 Jorge Ortiz presentó su charla de Tesis I de magíster titulada: "Attitude Analysis: a linguistic-based task for detailed position detection in texts"  ([slides](slides/2022-12-14 Jorge Ortiz.pdf)).
24. 07/12/2022 María José Zambrano presentó su charla de Tesis I de magíster titulada: "Comparison and Improvement of Bias Mitigation Algorithms for Word Embeddings"  ([slides](slides/2012-12-07 María José Zambrano.pdf)).
25. 22/07/2022 Mauricio Araneda presentó su charla de Tesis II de magíster titulada: "Computers making music? Measuring current progress with MUSIB evaluation" ([slides](slides/MUSIB Music Inpainting Benchmark.pdf)).
26. 13/07/2022 Se presentaron 3 charlas de Tesis I de magíster, 1) José Espina: Marco de trabajo de calibración rápida de confianza, en toma de decisiones asistidas por IA, 2) Alfonso Valderrama : Entropía de Shannon como medida de predictibilidad de sistemas de recomendación, 3)Ignacio Nuñez: Defining an extensible architecture for a multi-task GUI-oriented Machine Learning software.
27. 22/06/2022 [Juan Pablo Silva](https://jpsilva.cl/) presentó su charla de Tesis II de magíster titulada: "Logic-based interpretability of Graph Neural Networks"
28. 28/04/2022 [Miguel Cordero](https://orcid.org/0000-0003-4414-4447) del Servicio de Salud Metropolitano Sur Oriente de Santiago de Chile, nos presentó "Tendencias de la salud mental en los primeros 20 años de vida de usuarios/as de servicios de salud en el sur oriente de Santiago: ¿qué podemos aprender de las notas medicas?"
29. 05/01/2022 Rolando Kindelan nos dió una charla titulado "Análisis Topológico de Datos (TDA): antecedentes, actualidad y perspectivas"
30. 22/12/2021 El alumno de magíster [José Cañete](https://josecannete.github.io/) presentó su charla de tesis I: "Efficient models for Spanish NLP through Knowledge Distillation" ([slides](https://docs.google.com/presentation/d/1Nmo2o0Ey-LEc8d5zBklePvO8oXM3tRrlr2oc5s4oti0/edit?usp=sharing))([video](https://youtu.be/qybe09fGcuA))
31. 15/12/2021 El alumno de magíster Matías Rojas presentó su charla de tesis II titulada: Nested named entity recognition in diagnoses from the Chilean Waiting List in public hospitals  ([slides](slides/matiasrojastesisII.pdf))
32. 01/12/2021 Los alumnos de magíster Humberto Rodrigues y David Rojas presentaron sus charlas de Tesis I tituladas "Exploring bias metric strategies in contextualized embeddings" y "Word Embedding Bias Origin Detection".
33. 19/11/2021 Javier Muñoz presentó su trabajo de tesis de magíster: "Aprendizaje multi-instancia multi-etiqueta en la recomendación de intervenciones"
34. 29/09/2021 Cristian Ahumada presentó su trabajo: "Diseño y desarrollo de un software de apoyo para el aprendizaje del Mapuzugun"
35. 22/09/2021 Mauricio Araneda presentó un tutorial sobre VAEs. ([slides](slides/understanding_variational_encoders.pdf))
36. 01/09/2021 Pablo Badilla nos habló sobre su trabajo en el proyecto "lxs 400 "
37. 07/07/2021 Los alumnos de magíster Bastián Matamala, Mauricio Araneda y Gabriel Iturra presentaron sus charlas de Tesis I.
38. 05/05/2021  Carolina Chiu habló sobre el testeo de word embeddings en el contexto clínico.
39. 21/04/2021 [Cristián Candia](https://crcandia.github.io/crcandiav/) (UDD) nos habló sobre su trabajo en "Inteligencia Colectiva".
40. 14/04/2021 Gastón L'huillier nos habló sobre Machine Learning Engineering, infraestructura y todos los desafíos de poner en modelos en producción. ([slides](slides/Machine_Learning_Engineering_Gaston.pdf))
41. 24/03/2021 Andrés Abeliuk presentó su línea de investigación en tema de polarización.
42. 17/03/2021 Alan Ansell presentó su trabajo sobre PolyLM, un LM polísemico ([video](https://youtu.be/OKD8fvNZVwE))
43. 29/01/2021 Felipe Bravo dio un tutorial introductorio a la inferencia Bayesiana.
44. 20/01/2021 Daniel Diomedi presentó su charla de Tesis II sobre Question Answering sobre Wikidata usando Entity Linking and Neural Semantic Parsing.
45. 13/01/2021 Javier Vera presentó su trabajo sobre Aproximaciones computacionales a la diversidad lingüística de Sudamérica (la charla fue grabada).
46. 06/01/2021 Pablo Badilla presentó su trabajo sobre sesgo en word embeddings.
47. 23/12/2020 Bernardo Subercaseaux nos habló de su trabajo de investigación acerca de formalizaciones de interpretabilidad de modelos de aprendizaje automático desde el punto de vista de la complejidad computacional (slides, [video](https://youtu.be/7ZfDaFccl-8))
48. 17/12/2020 Jorge Ortiz nos habló sobre la lingüística sístemico funcional y sus potenciales vínculos con NLP. ([slides](https://ortizfuentes.com/wp-content/uploads/2020/12/Ortiz-J.-2020-Charla-El-aporte-de-los-estudios-del-lenguaje.pdf),[video](https://youtu.be/jRWyPl6cb7I))
49. 02/12/2020: Matías Rojas presentó su charla de Tesis I de magíster sobre nested NER en el Chilean Waiting List Corpus.
50. 11/11/2020: Cristián Tamblay presentó su trabajo de memoria sobre transferencia de modelos de sentimiento y emoción en distintos dominios.
51. 23/09/2020: Hernán Sarmiento practicó su charla de propuesta de tesis doctoral titulada: "A Domain-independent and Multilingual Approach for Crisis Event Detection and Understanding"
52. 09/09/2020: Cristian Ahumada presentó su charla de Tesis I de magíster titulada: "Diseño y desarrollo de una infraestructura computacional básica para el aprendizaje del Mapuzugun".([slides](slides/CharlaMapuzugun.pdf))
53. 12/08/2020: Javier Muñoz presentó su charla de Tesis I de magíster sobre multi-instance multi-label text classification para educación especial.
54. 05/08/2020: Frank Zamora practiced for his PhD qualification exam. He presented his work on Semantic Change Detection and his survey on word representations.
55. 20/05/2020: [Gonzalo Mena](https://gomena.github.io/) nos habló sobre "Métodos de estadística computacional y machine learning para las ciencias de la vida, con una aplicación a COVID-19." ([slides](slides/charla_gonzalo_mena.pdf)).
56. 04/03/2020: Carlos Castillo ([Chato](https://chato.cl/)) nos habló sobre "Fairness and Transparency in Rankings" ([slides](https://docs.google.com/presentation/d/1g8fKO8sL5zSTf4WMpziy-LiQrOI1rpHXpv9sZ2fljE0/edit?usp=sharing)).
57. 16/03/2019: [José Lezama](https://scholar.google.com/citations?user=iDP84cQAAAAJ&hl=en&oi=sra) de la Universidad de la República in Uruguay nos presentó su trabajo publicado en ICLR titulado: Revisiting non-linear PCA with progressively grown autoencoders.
58. 15/03/2019: Daniel Diomedi nos habló sobre su tema de tesis de magíster:  Improving Question Answering Systems over Wikidata.
59. 27/11/2019:  Andrés Abeliuk (University of Southern California), nos habló sobre el impacto de los algoritmos en la sociedad. Más [info](https://www.dcc.uchile.cl/charla-impacto-de-los-algoritmos-en-la-sociedad).
60. 16/10/2019: Rollan Rodríguez nos habló sobre métodos de clasificación usando topología.
61. 09/10/2019: Felipe González (alumno de la USM) nos presentó su trabajo sobre privacidad en el caso de Cambridge Analytica en Twitter. Su trabajo hace uso de word embeddings y open coding para encontrar asociaciones entre términos.
62. 02/10/2019: Jorge nos habló sobre dos papers de la familia de BERT que están en revisión en ICLR: 1) [ELECTRA](https://openreview.net/forum?id=r1xMH1BtvB) y 2) [ALBERT](https://openreview.net/forum?id=H1eA7AEtvS).

       1. Idea interesante de ELECTRA: tener dos redes adversariales donde la primera genera oraciones corrompidas pero altamente probables (se reemplazan ciertas palabras por un muestreo de la salida de una softmax). Esto reemplaza la idea de hacer masking en BERT. La segunda red recibe las oraciones corrompidas de la primera y aprende a discriminar las palabras originales de las falsas (esto se hace con un sigmoide).
       2. Idea interesante de ALBERT: usar un embedding layer de menor dimensionalidad que se aumenta luego con una capa de proyección. Esto reduce el número de parámetros respecto a BERT. Además se propone reemplazar la task de next sentence prediction por una que tome dos oraciones consecutivas, las desordene en algunos casos, y prediga si tienen el orden correcto. El argumento es que la tarea de next sentence prediction de BERT (que pone pares de oraciones aleatorias en los ejemplos negativos) es un muy simple.

63. 25/09/2019: [Wladmir Cardoso Brandão](http://www.wladmirbrandao.com) presentó [InferSent](https://github.com/facebookresearch/InferSent), una técnica para entrenar sentence embeddings usando datos de la Natural Language Inference task.
64. 11/09/2019: Henry Rosales presentó su artículo publicado en EMNLP sobre Entity Linking.
65. 04/09/2019: vimos la segunda parte del video de MultiTask Learning. Algunos conceptos interesantes: pointer networks (capas basadas en atención para copiar partes del input), anti-curriculum training (aprender primero lo más díficil para evitar quedar en óptimo local).
66. 28/08/2019: Jorge dió una clase sobre [XLNet](https://github.com/zihangdai/xlnet). Para llegar a XLNet hizo un repaso sobre Attention, Transformer y [BERT](https://arxiv.org/abs/1810.04805). Cosas destacables sobre XLNet: relative positional encoding y permutation language models. Un blog post que trata de digerir esto [aquí](http://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/).
67. 21/08/2019: Daniel Aguirre presentó su charla de tesis I de magíster sobre Transformers para resolver tareas algorítmicas.
68. 14/08/2019: Vimos [este](https://www.youtube.com/watch?v=M8dsZsEtEsg&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=18&t=0s) video sobre MultiTask learning de Richard Socher. Alcanzamos a ver la primera mitad. Lo paramos varias veces para procesarlo. La idea es usar QA como una tarea global donde se pueden instanciar muchas tareas de NLP (e.g., translation, entailment, sentiment analysis). Más info en [http://decanlp.com/](http://decanlp.com/). Quedamos en retomar el video más adelante y leer el paper con más profundidad.
69. 07/08/2019: Pablo Badilla presentó su propuesta de Tesis de Magíster sobre bias en Word Embeddings.



